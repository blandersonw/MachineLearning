{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFx/b2r3sJjczgZgHjsmtG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blandersonw/MachineLearning/blob/main/HW_5_1_BlakeAnderson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train polynomial SVC in this homework.\n",
        "\n",
        "Use the seed 0 everywhere.\n",
        "\n",
        "1. First, generate the two moon data as follows:\n",
        "\n",
        "\"X, y = make_moons(n_samples=200, noise=0.3, random_state=0)\"\n",
        "\n",
        "Plot the data.\n",
        "\n",
        "Randomly split the data into 80% training data and 20% testing data. Then split the training data again into 75% training data and 25% validation data. Keep this split fixed throughout the experiments.\n",
        "\n",
        "2. For each combinations of Cs = [1E-3,1E-2,1E-1,1E0,1E1,1E2,1E3] and ds = [2,3,4]\n",
        "(a) create a pipeline of polynomial features of degree d, standard scaler and linear SVC with the hyperparameter C\n",
        "(b) call fit(),\n",
        "(c) call predict() and measure training and validation error\n",
        "Report the training and validation error for each combination.\n",
        "\n",
        "3. Which combination has the smallest validation error? (You can manually find the minimum or you can use \"i, j = np.unravel_index(np.argmin(val_errors, axis=None), val_errors.shape)\" )\n",
        "\n",
        "4. Repeat 2 with a pipeline of standard scaler and SVC with the polynomial kernel of degree d, coef0=1, and the hyperparameter C.\n",
        "\n",
        "5. Repeat 3 with a pipeline of standard scaler and SVC .... (same as above)\n",
        "\n",
        "6. Should the results of 3 and 5 be identical? Or if not, why? Please comment."
      ],
      "metadata": {
        "id": "-sNVgFmHrA6n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slY7Ye15q90q"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=200, noise=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading data"
      ],
      "metadata": {
        "id": "-1mXu_iJ4wCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(len(X)):\n",
        "  if y[i] == 1:\n",
        "    plt.scatter(X[i][0], X[i][1], marker='^', color = \"red\")\n",
        "  if y[i] == 0:\n",
        "    plt.scatter(X[i][0], X[i][1], marker='o', color = \"blue\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "CFnzz4FY3lpe",
        "outputId": "14e345e1-d65d-4542-8ea4-a9f45048a92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the data"
      ],
      "metadata": {
        "id": "xmwcu6zA4yPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state = 0)\n",
        "\n",
        "X_train1, X_vali, y_train1, y_vali = train_test_split(X_train, y_train, test_size=.25, random_state = 0)"
      ],
      "metadata": {
        "id": "oaB0ggsJsnPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data"
      ],
      "metadata": {
        "id": "5610zEiT42MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "#various imports\n",
        "\n",
        "for d in [2,3,4]:\n",
        "  for c in [10**-3,10**-2,10**-1,1,10, 100, 1000]:\n",
        "\n",
        "    #double for loop to iterate through every d and c variation\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('Polynomial Features', PolynomialFeatures(degree=d)),\n",
        "        ('Scaler', StandardScaler()),\n",
        "        ('svm', LinearSVC(C=c, random_state=0)) \n",
        "    ])\n",
        "\n",
        "    #creating pipeline\n",
        "\n",
        "    pipeline.fit(X_train1,y_train1)\n",
        "\n",
        "    #fitting model\n",
        "\n",
        "    ypred_train1 = pipeline.predict(X_train1)\n",
        "    ypred_vali = pipeline.predict(X_vali)\n",
        "    mse_train1 = mean_squared_error(y_train1, ypred_train1)\n",
        "    mse_vali = mean_squared_error(y_vali, ypred_vali)\n",
        "\n",
        "    #using predictions to generate mean squared error for training and validation data\n",
        "\n",
        "    print(\"C value:\", str(c), \"-- D value:\", str(d), \"-- Training error\", str(mse_train1), \"-- Validation error\", str(mse_vali))\n",
        "\n",
        "    #printing results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hsmo_ZsrouR",
        "outputId": "6271beed-cda5-470f-df60-9570813ebbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C value: 0.001 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.2\n",
            "C value: 0.01 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 0.1 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 1 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.15\n",
            "C value: 10 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.15\n",
            "C value: 100 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.15\n",
            "C value: 1000 -- D value: 2 -- Training error 0.39166666666666666 -- Validation error 0.35\n",
            "C value: 0.001 -- D value: 3 -- Training error 0.175 -- Validation error 0.15\n",
            "C value: 0.01 -- D value: 3 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 0.1 -- D value: 3 -- Training error 0.16666666666666666 -- Validation error 0.125\n",
            "C value: 1 -- D value: 3 -- Training error 0.13333333333333333 -- Validation error 0.075\n",
            "C value: 10 -- D value: 3 -- Training error 0.11666666666666667 -- Validation error 0.05\n",
            "C value: 100 -- D value: 3 -- Training error 0.11666666666666667 -- Validation error 0.05\n",
            "C value: 1000 -- D value: 3 -- Training error 0.225 -- Validation error 0.225\n",
            "C value: 0.001 -- D value: 4 -- Training error 0.16666666666666666 -- Validation error 0.2\n",
            "C value: 0.01 -- D value: 4 -- Training error 0.15833333333333333 -- Validation error 0.175\n",
            "C value: 0.1 -- D value: 4 -- Training error 0.13333333333333333 -- Validation error 0.125\n",
            "C value: 1 -- D value: 4 -- Training error 0.11666666666666667 -- Validation error 0.1\n",
            "C value: 10 -- D value: 4 -- Training error 0.11666666666666667 -- Validation error 0.05\n",
            "C value: 100 -- D value: 4 -- Training error 0.10833333333333334 -- Validation error 0.15\n",
            "C value: 1000 -- D value: 4 -- Training error 0.1 -- Validation error 0.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimum validation error of .05 for D-val 3 and C-vals 10, 100 AND D-val 4 and C-val 10."
      ],
      "metadata": {
        "id": "7_P3jLPR1QB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for d in [2,3,4]:\n",
        "  for c in [10**-3,10**-2,10**-1,1,10, 100, 1000]:\n",
        "    pipeline = Pipeline([\n",
        "        ('Scaler', StandardScaler()),\n",
        "        ('svm', SVC(kernel = \"poly\", C=c, coef0=1, degree = d)) \n",
        "    ])\n",
        "\n",
        "    #creating pipeline\n",
        "\n",
        "    pipeline.fit(X_train1,y_train1)\n",
        "\n",
        "    #fitting model\n",
        "\n",
        "    ypred_train1 = pipeline.predict(X_train1)\n",
        "    ypred_vali = pipeline.predict(X_vali)\n",
        "    mse_train1 = mean_squared_error(y_train1, ypred_train1)\n",
        "    mse_vali = mean_squared_error(y_vali, ypred_vali)\n",
        "\n",
        "    #using predictions to generate mean squared error for training and validation data\n",
        "\n",
        "    print(\"C value:\", str(c), \"-- D value:\", str(d), \"-- Training error\", str(mse_train1), \"-- Validation error\", str(mse_vali))\n",
        "\n",
        "    #printing results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nscPvbw30iz9",
        "outputId": "ef8c2d6e-d473-4866-a05b-b1caf457d078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C value: 0.001 -- D value: 2 -- Training error 0.48333333333333334 -- Validation error 0.5\n",
            "C value: 0.01 -- D value: 2 -- Training error 0.175 -- Validation error 0.2\n",
            "C value: 0.1 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 1 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 10 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 100 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 1000 -- D value: 2 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 0.001 -- D value: 3 -- Training error 0.45 -- Validation error 0.475\n",
            "C value: 0.01 -- D value: 3 -- Training error 0.16666666666666666 -- Validation error 0.2\n",
            "C value: 0.1 -- D value: 3 -- Training error 0.16666666666666666 -- Validation error 0.15\n",
            "C value: 1 -- D value: 3 -- Training error 0.13333333333333333 -- Validation error 0.075\n",
            "C value: 10 -- D value: 3 -- Training error 0.13333333333333333 -- Validation error 0.075\n",
            "C value: 100 -- D value: 3 -- Training error 0.125 -- Validation error 0.05\n",
            "C value: 1000 -- D value: 3 -- Training error 0.125 -- Validation error 0.05\n",
            "C value: 0.001 -- D value: 4 -- Training error 0.25 -- Validation error 0.25\n",
            "C value: 0.01 -- D value: 4 -- Training error 0.16666666666666666 -- Validation error 0.175\n",
            "C value: 0.1 -- D value: 4 -- Training error 0.13333333333333333 -- Validation error 0.125\n",
            "C value: 1 -- D value: 4 -- Training error 0.125 -- Validation error 0.125\n",
            "C value: 10 -- D value: 4 -- Training error 0.125 -- Validation error 0.05\n",
            "C value: 100 -- D value: 4 -- Training error 0.11666666666666667 -- Validation error 0.1\n",
            "C value: 1000 -- D value: 4 -- Training error 0.1 -- Validation error 0.175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimum validation error of .05 for D-val 3 and C-vals 100, 1000 AND D-val 4 and C-val 10."
      ],
      "metadata": {
        "id": "jmTV8CVr2znZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of 3 and 5 should not be identical, however, it makes sense that they are very similar.  The kernel trick uses an estimation of the cross product rather than estimating using polynomial transformation itself.  "
      ],
      "metadata": {
        "id": "uLd_eyK53FBH"
      }
    }
  ]
}